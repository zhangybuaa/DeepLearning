欠拟合现象：模型无法达到一个较低的误差
过拟合现象：训练误差较低但是泛化误差依然较高，二者相差较大，训练样本不足

训练误差（training error）：模型在训练数据集上表现出的误差
泛化误差（generalization error）：模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似

验证数据集：
从给定的训练集中随机选取一小部分作为验证集，而将剩余部分作为真正的训练集

K折交叉验证
把原始训练数据集分割成K个不重合的子数据集，然后我们做K次模型训练和验证。
每一次，我们使用一个子数据集验证模型，并使用其他K-1个子数据集来训练模型。
在这K次训练和验证中，每次用来验证模型的子数据集都不同。最后，我们对这K次训练误差和验证误差分别求平均。


面对过拟合的问题，通常要采用的办法是正则化，正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，
L2范数正则化在模型原损失函数基础上添加L2范数惩罚项
L2范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积


另一个方法是dropput的方法，当对该隐藏层使用丢弃法时，该层的隐藏单元将有一定概率被丢弃掉
